---
title: 'Assignment 3'
author: "Bailey Bradford, Frances Murray, Jonathan Zisk"
date: "April 2024"
output:
  html_document:
    theme: cosmo 
    toc: true
    toc_float: true
    toc_depth: 4
    code_folding: hide
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, cache = TRUE, warning = FALSE, results = "hide")
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)

library(dplyr)
library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(classInt) 
library(tmap)
library(gt)
library(gtExtras)
# for KDE and ML risk class intervals
# functions
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"

source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

```

## Read in Data from Phoenix


```{r load_data}


street_posts <- st_read("https://mapping-phoenix.opendata.arcgis.com/api/download/v1/items/6f41dcc9c5f547569e4ddd35d4b83a51/geojson?layers=0") %>% 
  dplyr::select(OBJECTID) %>% 
  st_transform('ESRI:103223')

police_grid <- st_read("https://mapping-phoenix.opendata.arcgis.com/api/download/v1/items/5bdb7c621a6449bfb6e190e4c09a6636/geojson?layers=0") %>% 
  st_transform(st_crs(street_posts))

phx <- st_union(police_grid) %>% 
    st_transform(st_crs(street_posts))


library(data.table)

#load crime data
crime_data <- read.csv("crime-data_crime-data_crimestat.csv")

#get rid of space in column names
names(crime_data) <- gsub(x = names(crime_data), pattern = " ", replacement = "_")

#select for car theft and year 2022
car_theft_22 <- crime_data %>% 
  filter(UCR.CRIME.CATEGORY == "MOTOR VEHICLE THEFT" &
    grepl("2022" , OCCURRED.ON)) 

#select for drug offense and year 2022
drug_off_2022 <- crime_data %>% 
  filter(UCR.CRIME.CATEGORY == "DRUG OFFENSE" &
    grepl("2022" , OCCURRED.ON)) 
 


```

## visualizing point data

Plotting point data and density

> How do we analyze point data?

> Are there other geometries useful to represent point locations?

```{r  fig.height=11, results='markup'}

# Street lights

tm_shape(phx)+ 
  tm_borders()+ 
  tm_shape(street_posts)+ 
  tm_dots(size = .0001)+ 
  tm_layout (main.title = "Distribution of streetlamps in Phoenix")

# Plot 2: Density of street lamps with contours overlaid on Phoenix boundary
ggplot() + 
    geom_sf(data = phx, fill = "lightgrey") +  # Add boundary with grey fill
    stat_density2d(data = data.frame(st_coordinates(street_posts)),  # Compute 2D kernel density estimate
                   aes(X, Y, fill = ..level.., alpha = ..level..),  # Define aesthetics for density contours
                   size = 0.01, bins = 40, geom = 'polygon') +  # Set size and number of bins for contours
    scale_colour_brewer(palette = "Reds") +  # Use Viridis color scale for fill
    scale_alpha(range = c(0.00, 0.35), guide = FALSE) +  # Set transparency range for contours
    labs(title = "Density of Street Lamps in Phoenix") +  # Set plot title
    theme_void() + theme(legend.position = "none")  # Use a blank theme and remove legend


```

```{r results='markup', fig.width=6, fig.height=4}

#summarize car theft by police grid

car_theft_22_grid <- car_theft_22 %>% 
  dplyr::select(c(INC.NUMBER, GRID)) %>% 
  group_by(GRID) %>% 
  summarise(n_car_theft = n()) 

#summarize drug offense by police grid

drug_off_22_grid <- drug_off_2022 %>% 
  dplyr::select(c(INC.NUMBER, GRID)) %>% 
  group_by(GRID) %>% 
  summarise(n_drug_off = n()) 

#Join car theft to grid 

police_grid_count <- police_grid %>% 
  st_drop_geometry() %>% 
  left_join(car_theft_22_grid, join_by("GRID_NUMBER" == "GRID")) %>% 
  mutate(n_car_theft = if_else(is.na(n_car_theft), 0, n_car_theft)) %>% 
  left_join(police_grid) %>% 
  left_join(drug_off_22_grid, join_by("GRID_NUMBER" == "GRID")) %>%
  replace(is.na(.), 0) %>% 
  st_as_sf()





```


### Aggregate street lamps to the police grid

```{r spatialjoin}
## add a value of 1 to each crime, sum them with aggregate

street_posts_count <- street_posts %>% 
  dplyr::select(OBJECTID) %>% 
  mutate(count_posts = 1) %>% 
  aggregate(.,police_grid, sum)  %>% 
  mutate(count_posts = replace_na(count_posts, 0)) 

tm_shape(street_posts_count) + 
  tm_fill("count_posts", 
          palette = "Reds", 
          style = "jenks", 
          n = 7)+ 
  tm_shape(phx)+ 
  tm_borders()+ 
    tm_layout(legend.outside = TRUE, 
              main.title = "Count Street Lamps")



```

## Nearest Neighbor Feature


```{r knn}
# Convenience aliases to reduce the length of function names
st_c    <- st_coordinates  # Alias for st_coordinates function
st_coid <- st_centroid     # Alias for st_centroid function

# Create nearest neighbor (NN) relationship from abandoned cars data to fishnet grid cells
street_posts_grid <- police_grid_count %>%  # Start with the summarized variables data
    mutate(street_posts.nn = nn_function(  # Create a new column for nearest neighbor information
        st_c(st_coid(police_grid_count)),  # Calculate centroids of fishnet grid cells
        st_c(street_posts),         # Get coordinates of abandoned cars
        k = 10                      # Number of nearest neighbors to find
    ))

```


```{r extra data for final net}

phx_villages <- st_read("https://maps.phoenix.gov/pub/rest/services/Public/Villages/MapServer/0/query?outFields=*&where=1%3D1&f=geojson") %>% 
  st_transform(st_crs(street_posts))

police_districts <- st_read("https://maps.phoenix.gov/pub/rest/services/Public/PolicePrecincts/MapServer/0/query?outFields=*&where=1%3D1&f=geojson") %>% 
  st_transform(st_crs(street_posts))
```

```{r final net}

final_net <-
  st_centroid(street_posts_grid) %>%
    st_join(phx_villages %>% 
              dplyr::select(NAME)) %>% 
    st_join(police_districts %>% 
              dplyr::select(NAME)) %>% 
      st_drop_geometry %>% 
      left_join(police_grid %>% 
                  dplyr::select(GRID_NUMBER, geometry)) %>% 
      st_sf() %>% 
  rename("VILLAGE" = NAME.x, 
         "PRECINCT" = NAME.y) %>% 
  st_join(street_posts_count %>% 
              dplyr::select(count_posts)) %>% 
  na.omit() 
  
```

```{r vizNN}
## Visualize the NN feature
vars_net.long.nn <- 
  dplyr::select(final_net, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

```
#small multiple of risk factors in the fishnet 

```{r}

vars_net.long.nn <- vars_net.long.nn %>% 
  mutate(log_val = log(value))

tm <- tm_shape(vars_net.long.nn)+ 
  tm_fill("log_val", 
          palette = "Spectral", 
          n= 8)+ 
  tm_shape(phx)+ 
  tm_borders()+   
  tm_layout(legend.outside = TRUE, 
            main.title = "Log Street Lamp NN")


tm2 <- tm_shape(police_grid_count)+ 
  tm_fill("n_car_theft", palette = "PuBuGn", style = "jenks", n= 7)+ 
  tm_shape(phx)+ 
  tm_borders()+ 
    tm_layout(legend.outside = TRUE, 
              main.title = "Count Drug Offense")


tmap_arrange(tm, tm2)

```

## Small multiple scatterplot with correlations

```{r fig.width = 10}

corr_plots <- final_net %>% 
  st_drop_geometry() %>% 
  dplyr::select(GRID_NUMBER, n_car_theft, n_drug_off, street_posts.nn, count_posts) %>% 
  pivot_longer(cols= c(n_drug_off, street_posts.nn, count_posts),
               names_to = "metric", 
               values_to = "value") %>% 
  mutate(metric = recode(metric, "count_posts" = "Street Lamps per Grid Cell", 
                         "n_drug_off" = "Drug Offenses per Grid Cell", 
                         "street_posts.nn" = "Lamp Post NN distance (ft)"))
 

ggplot(corr_plots, 
       aes(x= n_car_theft, 
           y= value, 
           color = metric))+ 
  geom_point(size = .5)+ 
  facet_wrap(~metric, scales = "free")+ 
  scale_y_log10()+ 
  geom_smooth(color = "black", lwd = .5)+ 
  labs(x= "Number of car thefts")

?pivot_longer()
```


## Histogram of dependent variable

```{r}

library(scales)

ggplot(final_net, 
       aes(x= n_car_theft))+
  geom_histogram(fill = "turquoise", col = "white")+ 
  xlim(0, 30)+ 
  labs( x = "Number of car thefts", 
        y= "Count", 
        title = "Histogram of Phoenix car thefts in 2022, by grid")+ 
  scale_y_continuous(labels = label_comma(), 
                     limits = c(0,2500)) 

```


## Local Moran's I for fishnet grid cells

using {spdep} package to to build neighborhood weights and list to calculate local Moran's I.

Note that the code here is *different* than in the book - it has been updated to keep up with changes in packages.

> What is the difference between local and global Moran's I?

A little in depth version of the chunk below can be found:

Mendez C. (2020). Spatial autocorrelation analysis in R. R Studio/RPubs. Available at <https://rpubs.com/quarcs-lab/spatial-autocorrelation>

```{r final_net.weights}
## generates warnings from PROJ issues
## {spdep} to make polygon to neighborhoods... 
final_net.nb <- poly2nb(as_Spatial(final_net), queen=TRUE)
## ... and neighborhoods to list of weights
final_net.weights <- nb2listw(final_net.nb, style="W", zero.policy=TRUE)

# print(final_net.weights, zero.policy=TRUE)
```

```{r local_morans}
local_morans <- localmoran(final_net$count_posts, final_net.weights, zero.policy=TRUE, 
                           alternative = "two.sided") %>% 
  as.data.frame() %>% 
  rename(p_value = 'Pr(z != E(Ii))')

### join local Moran's I results to fishnet
mp <- moran.plot(as.vector(scale(final_net$count_posts)), final_net.weights)

head(mp)

final_net.localMorans <- 
  cbind(local_morans, as.data.frame(final_net)) %>% 
  st_sf() %>%
  dplyr::select(n_car_theft = n_car_theft,
                street_lamps_count = count_posts, 
                Local_Morans_I = Ii,) %>% 
  mutate(hot_cold_spots = case_when((mp$x >= 0 & mp$wx >= 0) & (local_morans$p_value <= 0.05) ~ 1,
                                    (mp$x <= 0 & mp$wx <= 0) & (local_morans$p_value <= 0.05) ~ 0,
                                    TRUE ~ NA)) %>% 
  gather(Variable, Value, -geometry)

## 

```

### Plotting local Moran's I results

This is a complex code chunk - it's a loop which builds ggplots of local Moran's for each of your `vars`

> What does a significant hot spot tell us about the distribution of burglaries?

```{r local_morans.plot, fig.width=10, fig.height=4}
## This is just for plotting
vars <- unique(final_net.localMorans$Variable)
varList <- list()

for(i in vars){
  varList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(final_net.localMorans, Variable == i), 
              aes(fill = Value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      theme_void() + theme(legend.position="bottom")}

do.call(grid.arrange,c(varList, ncol = 4, top = "Local Morans I statistics, Streetlamps"))

```

## Distance to Hot spot

Using NN distance to a hot spot location

```{r}
# generates warning from NN
final_net <- final_net %>% 
  mutate(lamp.isSig = 
           ifelse(local_morans[,5] <= 0.001, 1, 0)) %>%
  mutate(lamp.isSig.dist = 
           nn_function(st_c(st_coid(final_net)),
                       st_c(st_coid(filter(final_net, 
                                           lamp.isSig == 1))), 
                       k = 1))

## What does k = 1 represent?
```

> What does `k = 1` above mean in terms of measuring nearest neighbors?

### Plot NN distance to hot spot

```{r}
ggplot() +
      geom_sf(data = final_net, aes(fill=lamp.isSig.dist), colour=NA) +
      scale_fill_viridis(name="NN Distance") +
      labs(title="Streetlamp NN Distance") +
      theme_void()

```

## Modeling and CV

Leave One Group Out CV on spatial features

```{r results='hide'}

# View(crossValidate)

## define the variables we want
reg.ss.vars <- c("street_posts.nn", "lamp.isSig.dist")

## RUN REGRESSIONS
reg.ss.spatialCV <- crossValidate(
  dataset = final_net,
  id = "VILLAGE",                           
  dependentVariable = "n_car_theft",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = VILLAGE, n_car_theft, Prediction, geometry)


## define the variables we want
reg.ss.vars2 <- c("street_posts.nn", "lamp.isSig.dist", "n_drug_off")

## RUN REGRESSIONS
reg.ss.spatialCV2 <- crossValidate(
  dataset = final_net,
  id = "VILLAGE",                           
  dependentVariable = "n_car_theft",
  indVariables = reg.ss.vars2) %>%
    dplyr::select(cvID = VILLAGE, n_car_theft, Prediction, geometry)



```

```{r fig.width = 8, results='markup'}
# calculate errors by Village

error_by_reg_and_fold <- 
  reg.ss.spatialCV %>%
    group_by(cvID)  %>% 
    summarize(Mean_Error = mean(Prediction - n_car_theft, na.rm = T),
              MAE = mean(abs(Mean_Error), na.rm = T),
              SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup() %>% 
  mutate(reg = "Regression 1")

error_by_reg_and_fold2 <- 
  reg.ss.spatialCV2 %>%
    group_by(cvID) %>% 
    summarize(Mean_Error = mean(Prediction - n_car_theft, na.rm = T),
              MAE = mean(abs(Mean_Error), na.rm = T),
              SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup() %>% 
  mutate(reg = "Regression 2")

errors_combined <- rbind(error_by_reg_and_fold, error_by_reg_and_fold2)

errors_combined %>% 
  arrange(desc(MAE))
errors_combined %>% 
  arrange(MAE)

errors_table <- errors_combined %>% 
  st_drop_geometry() %>% 
  pivot_wider(names_from = "reg", 
              values_from = c("Mean_Error", "MAE", "SD_MAE"))

?pivot_wider

##Table

errors_table %>% 
  gt() %>% 
  tab_spanner(columns = 2:3, 
              label = "Mean Error") %>% 
  tab_spanner(columns = 4:5, 
              label = "Mean Abs. Error") %>% 
  tab_spanner(columns = 6:7, 
              label = "Std. Dev. Mean Abs. Error") %>% 
  cols_label("cvID" = "Village",
             "Mean_Error_Regression 1" = "Reg.1", 
             "Mean_Error_Regression 2" = "Reg. 2", 
             "MAE_Regression 1" = "Reg. 1", 
             "MAE_Regression 2" = "Reg. 2", 
             "SD_MAE_Regression 1" = "Reg. 1", 
             "SD_MAE_Regression 2" = "Reg. 2") %>% 
  fmt_number(columns = 2:7, 
              decimals = 2) %>% 
    cols_width(2:7 ~ px(100)) %>% 
  opt_stylize(style = 6, color = "gray") %>% 
  gt_theme_538()

```

```{r plot and map of errors, results='markup'}

## plot histogram of OOF (out of fold) errors
error_by_reg_and_fold %>%
  ggplot(aes(MAE)) + 
    geom_histogram(bins = 30, colour="black", fill = "#FDE725FF") +
  scale_x_continuous() + 
    labs(title="Distribution of MAE", subtitle = "LOGO-CV",
         x="Mean Absolute Error", y="Count") 

tm_shape(errors_combined)+ 
  tm_polygons(fill = "Mean_Error", 
              palette = "RdYlGn",
              lwd = 0, n= 8)+ 
    tm_facets(by = "reg") + 
  tm_layout(legend.outside = TRUE, 
            legend.outside.position	 = "right")
```

## Density vs predictions

The `spatstat` function gets us kernal density estimates with varying search radii.

Note that the code here is *different* than in the book - it has been updated to keep up with changes in packages.


```{r}
theft_sf <- st_as_sf(final_net) 

# demo of kernel width
theft_ppp <- as.ppp(st_coordinates(theft_sf), W = st_bbox(final_net))
theft_KD.1000 <- density.ppp(theft_ppp, 1000)
theft_KD.1500 <- density.ppp(theft_ppp, 1500)
theft_KD.2000 <- density.ppp(theft_ppp, 2000)
theft_KD.df <- rbind(
  mutate(data.frame(rasterToPoints(mask(raster(theft_KD.1000), as(phx_villages, 'Spatial')))), Legend = "1000 Ft."),
  mutate(data.frame(rasterToPoints(mask(raster(theft_KD.1500), as(phx_villages, 'Spatial')))), Legend = "1500 Ft."),
  mutate(data.frame(rasterToPoints(mask(raster(theft_KD.2000), as(phx_villages, 'Spatial')))), Legend = "2000 Ft.")) 

theft_KD.df$Legend <- factor(theft_KD.df$Legend, levels = c("1000 Ft.", "1500 Ft.", "2000 Ft."))

ggplot(data=theft_KD.df, aes(x=x, y=y)) +
  geom_raster(aes(fill=layer)) + 
  facet_wrap(~Legend) +
  coord_sf(crs=st_crs(final_net)) + 
  scale_fill_viridis(name="Density") +
  labs(title = "Kernel density with 3 different search radii") +
  mapTheme(title_size = 14)
```

```{r}

as.data.frame(theft_KD.1000) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) %>%
   ggplot() +
     geom_sf(aes(fill=value),
             color = NA) +
     geom_sf(data = sample_n(street_posts, 1500), size = .1, col = "white", alpha = 0.5) +
     scale_fill_viridis(name = "Density") +
     labs(title = "Kernel density of car thefts") +
     mapTheme(title_size = 14)
```

## Get 2018 crime data

Let's see how our model performed relative to KD on the following year's data.

```{r car_theft_23}
car_theft_23 <- crime_data %>% 
  filter(UCR.CRIME.CATEGORY == "MOTOR VEHICLE THEFT" &
           grepl("2023", OCCURRED.ON)) %>% 
  left_join(police_grid %>% 
              dplyr::select(-OBJECTID),
            by= c("GRID" = "GRID_NUMBER")) %>% 
  st_sf() %>% 
  st_transform(st_crs(street_posts))
```



```{r}
theft_KDE_sum <- as.data.frame(theft_KD.1000) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) 
kde_breaks <- classIntervals(theft_KDE_sum$value, 
                             n = 5, "fisher")
theft_KDE_sf <- theft_KDE_sum %>%
  mutate(label = "Kernel Density",
         Risk_Category = classInt::findCols(kde_breaks),
         Risk_Category = case_when(
           Risk_Category == 5 ~ "5th",
           Risk_Category == 4 ~ "4th",
           Risk_Category == 3 ~ "3rd",
           Risk_Category == 2 ~ "2nd",
           Risk_Category == 1 ~ "1st")) %>% 
  cbind(
    aggregate(
      dplyr::select(car_theft_23) %>% mutate(n_theft = 1), ., sum) %>%
    mutate(n_theft = replace_na(n_theft, 0))) %>%
  dplyr::select(label, Risk_Category, n_theft)
```



```{r}
ml_breaks <- classIntervals(reg.ss.spatialCV$Prediction, 
                             n = 5, "fisher")
theft_risk_sf <-
  reg.ss.spatialCV %>%
  mutate(label = "Risk Predictions",
         Risk_Category =classInt::findCols(ml_breaks),
         Risk_Category = case_when(
           Risk_Category == 5 ~ "5th",
           Risk_Category == 4 ~ "4th",
           Risk_Category == 3 ~ "3rd",
           Risk_Category == 2 ~ "2nd",
           Risk_Category == 1 ~ "1st")) %>%
  cbind(
    aggregate(
      dplyr::select(car_theft_23) %>% mutate(n_theft = 1), ., sum) %>%
      mutate(n_theft = replace_na(n_theft, 0))) %>%
  dplyr::select(label,Risk_Category, n_theft)
  
```

We don't do quite as well because we don't have very many features, but still pretty good.

```{r}
rbind(theft_KDE_sf, theft_risk_sf) %>%
  na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category, -geometry) %>%
  ggplot() +
    geom_sf(aes(fill = Risk_Category), colour = NA) +
    geom_sf(data = sample_n(street_posts, 3000), size = .5, colour = "white", alpha = .5) +
    facet_wrap(~label, ) +
    scale_fill_viridis(discrete = TRUE) +
    labs(title="Comparison of Kernel Density and Risk Predictions",
         subtitle="2022 car theft risk predictions; 2023 car thefts") +
    mapTheme(title_size = 14)
```

```{r}
rbind(theft_KDE_sf, theft_risk_sf) %>%
  st_drop_geometry() %>%
  na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category) %>%
  group_by(label, Risk_Category) %>%
  summarize(n_theft = sum(Value)) %>%
  ungroup() %>%
  group_by(label) %>%
  mutate(Pcnt_of_test_set_crimes = n_theft / sum(n_theft)) %>%
    ggplot(aes(Risk_Category,Pcnt_of_test_set_crimes)) +
      geom_bar(aes(fill=label), position="dodge", stat="identity") +
      scale_fill_viridis(discrete = TRUE, name = "Model") +
      labs(title = "Risk prediction vs. Kernel density, 2023 Car Thefts",
           y = "% of Test Set Car Thefts (per model)",
           x = "Risk Category") +
  theme_bw() +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.5))
```

## Appendix? 

```{r map of street lamps in dot form, fig.height=11}

# Street lights

tm_shape(phx)+ 
  tm_borders()+ 
  tm_shape(street_posts)+ 
  tm_dots(size = .005)+ 
  tm_layout (main.title = "Distribution of streetlamps in Phoenix")



```


## Junk don't keep 

```{r eval=FALSE}

library(mapview)

mapview(final_net, zcol = "PRECINCT", palette = "Spectral")

street_posts_count <- street_posts %>% 
  st_join(police_grid, join = st_within) %>% 
  group_by(GRID_NUMBER) %>% 
  summarise(count = n()) %>% 
  st_drop_geometry() %>%
  rename("n_lamps" = count)

```

